{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полный процесс обработки данных и обучения моделей\n",
    "\n",
    "В этом ноутбуке мы будем выполнять следующие шаги:\n",
    "1. Генерация датасета.\n",
    "2. Нормализация координат и вычисление углов.\n",
    "3. Обучение моделей (нейросеть, градиентный бустинг, SVM).\n",
    "4. Предсказание с использованием обученных моделей.\n",
    "5. Оценка точности моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Количество образцов для генерации\n",
    "num_samples_per_class = 500\n",
    "\n",
    "# Функция генерации случайных 3D координат\n",
    "def generate_3d_point():\n",
    "    return np.random.uniform(-1, 1, 3)\n",
    "\n",
    "# Функция определения, согнута ли рука\n",
    "def is_bent(shoulder, elbow, wrist):\n",
    "    upper_arm = np.linalg.norm(elbow - shoulder)\n",
    "    forearm = np.linalg.norm(wrist - elbow)\n",
    "    total_length = np.linalg.norm(wrist - shoulder)\n",
    "    return 1 if total_length < (upper_arm + forearm) * 0.95 else 0\n",
    "\n",
    "# Генерация датасета\n",
    "data = []\n",
    "while len(data) < num_samples_per_class * 2:\n",
    "    shoulder = generate_3d_point()\n",
    "    elbow = generate_3d_point()\n",
    "    wrist = generate_3d_point()\n",
    "    label = is_bent(shoulder, elbow, wrist)\n",
    "    if label == 1 and len([d for d in data if d[-1] == 1]) < num_samples_per_class:\n",
    "        data.append(np.concatenate([shoulder, elbow, wrist, [label]]))\n",
    "    elif label == 0 and len([d for d in data if d[-1] == 0]) < num_samples_per_class:\n",
    "        data.append(np.concatenate([shoulder, elbow, wrist, [label]]))\n",
    "\n",
    "# Создание DataFrame\n",
    "columns = ['shoulder_x', 'shoulder_y', 'shoulder_z', \n",
    "           'elbow_x', 'elbow_y', 'elbow_z', \n",
    "           'wrist_x', 'wrist_y', 'wrist_z', \n",
    "           'label']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Сохранение в CSV\n",
    "df.to_csv('../data/raw/dataset.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация координат и вычисление углов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Локальный путь к аннотациям COCO\n",
    "COCO_ANNOTATIONS_PATH = \"../data/person_keypoints_train2017.json\"\n",
    "\n",
    "# Убедитесь, что файл существует\n",
    "if not os.path.exists(COCO_ANNOTATIONS_PATH):\n",
    "    raise FileNotFoundError(f\"File not found: {COCO_ANNOTATIONS_PATH}\")\n",
    "\n",
    "# Загружаем аннотации COCO\n",
    "coco = COCO(COCO_ANNOTATIONS_PATH)\n",
    "\n",
    "# Ключевые точки тела\n",
    "KEYPOINTS = {\"left_shoulder\": 5, \"right_shoulder\": 6,\n",
    "             \"left_elbow\": 7, \"right_elbow\": 8,\n",
    "             \"left_wrist\": 9, \"right_wrist\": 10}\n",
    "\n",
    "# Функция нормализации координат\n",
    "def normalize_coords(coords):\n",
    "    coords = np.array(coords, dtype=np.float32)\n",
    "    min_val, max_val = np.min(coords, axis=0), np.max(coords, axis=0)\n",
    "    return (coords - min_val) / (max_val - min_val)\n",
    "\n",
    "# Функция вычисления угла в локте\n",
    "def elbow_angle(shoulder, elbow, wrist):\n",
    "    vec1 = np.array(elbow) - np.array(shoulder)\n",
    "    vec2 = np.array(wrist) - np.array(elbow)\n",
    "    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0)) * 180 / np.pi\n",
    "    return angle\n",
    "\n",
    "# Создаем DataFrame для хранения данных\n",
    "columns = ['shoulder_x', 'shoulder_y', 'elbow_x', 'elbow_y', 'wrist_x', 'wrist_y', 'angle', 'arm_state']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Выбираем изображения с людьми\n",
    "image_ids = coco.getImgIds(catIds=[1])  # ID людей\n",
    "\n",
    "for image_id in image_ids:\n",
    "    image_data = coco.loadImgs(image_id)[0]\n",
    "    annotation_ids = coco.getAnnIds(imgIds=image_data['id'], catIds=[1])\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "    # Извлекаем координаты ключевых точек\n",
    "    for ann in annotations:\n",
    "        keypoints = ann[\"keypoints\"]\n",
    "        left_shoulder = keypoints[KEYPOINTS[\"left_shoulder\"] * 3:KEYPOINTS[\"left_shoulder\"] * 3 + 2]\n",
    "        left_elbow = keypoints[KEYPOINTS[\"left_elbow\"] * 3:KEYPOINTS[\"left_elbow\"] * 3 + 2]\n",
    "        left_wrist = keypoints[KEYPOINTS[\"left_wrist\"] * 3:KEYPOINTS[\"left_wrist\"] * 3 + 2]\n",
    "\n",
    "        # Нормализуем координаты\n",
    "        norm_coords = normalize_coords([left_shoulder, left_elbow, left_wrist])\n",
    "\n",
    "        # Вычисляем угол\n",
    "        angle = elbow_angle(norm_coords[0], norm_coords[1], norm_coords[2])\n",
    "        arm_state = \"Согнута\" if angle < 150 else \"Разогнута\"\n",
    "\n",
    "        # Добавляем данные в DataFrame\n",
    "        df = df.append({\n",
    "            'shoulder_x': norm_coords[0][0],\n",
    "            'shoulder_y': norm_coords[0][1],\n",
    "            'elbow_x': norm_coords[1][0],\n",
    "            'elbow_y': norm_coords[1][1],\n",
    "            'wrist_x': norm_coords[2][0],\n",
    "            'wrist_y': norm_coords[2][1],\n",
    "            'angle': angle,\n",
    "            'arm_state': arm_state\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Визуализируем\n",
    "        plt.scatter(norm_coords[:, 0], norm_coords[:, 1], color=['r', 'g', 'b'])\n",
    "        plt.plot(norm_coords[:, 0], norm_coords[:, 1], 'k-')\n",
    "        plt.title(f\"Угол: {angle:.2f}° ({arm_state})\")\n",
    "        plt.show()\n",
    "        break  # Только одно изображение\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение данных в CSV файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем DataFrame в CSV файл\n",
    "df.to_csv('../data/normalized_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей (нейросеть, градиентный бустинг, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from models.model import NeuralNetwork\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки данных\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[['wrist_x', 'wrist_y', 'wrist_z', 'elbow_x', 'elbow_y', 'elbow_z', 'shoulder_x', 'shoulder_y', 'shoulder_z']]\n",
    "    y = data['label']\n",
    "    return X, y\n",
    "\n",
    "# Функция обучения нейросети\n",
    "def train_neural_network(X_train, y_train, X_val, y_val):\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    num_classes = 1\n",
    "    model = NeuralNetwork(input_shape, num_classes)\n",
    "    model.build_model()\n",
    "    model.train(X_train, y_train, X_val, y_val)\n",
    "    model.save('../models/model_nn.h5')\n",
    "\n",
    "# Функция обучения градиентного бустинга\n",
    "def train_gradient_boosting(X_train, y_train):\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, '../models/model_gb.pkl')\n",
    "\n",
    "# Функция обучения SVM\n",
    "def train_svm(X_train, y_train):\n",
    "    model = SVC(probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, '../models/model_svm.pkl')\n",
    "\n",
    "# Основная функция\n",
    "def main(model_type):\n",
    "    # Загрузка датасета\n",
    "    X, y = load_data('../data/processed/processed_dataset.csv')\n",
    "    \n",
    "    # Разделение датасета на обучающую и валидационную выборки\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if model_type == 'nn':\n",
    "        train_neural_network(X_train, y_train, X_val, y_val)\n",
    "    elif model_type == 'gb':\n",
    "        train_gradient_boosting(X_train, y_train)\n",
    "    elif model_type == 'svm':\n",
    "        train_svm(X_train, y_train)\n",
    "    else:\n",
    "        print(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting, or 'svm' for support vector machine.\")\n",
    "\n",
    "# Пример вызова функции для обучения нейросети\n",
    "main('nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание с использованием обученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки модели\n",
    "def load_model(model_type):\n",
    "    if model_type == 'nn':\n",
    "        return tf.keras.models.load_model('../models/model_nn.h5')\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        return joblib.load(f'../models/model_{model_type}.pkl')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting, or 'svm' for support vector machine\")\n",
    "\n",
    "# Функция предсказания состояния руки\n",
    "def predict_arm_position(model, points, model_type):\n",
    "    points = np.array(points).reshape(1, -1)\n",
    "    if model_type == 'nn':\n",
    "        prediction = model.predict(points)\n",
    "        return int(np.round(prediction[0][0]))\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        prediction = model.predict(points)\n",
    "        return int(prediction[0])\n",
    "\n",
    "# Пример использования функции предсказания\n",
    "model_type = 'nn'\n",
    "model = load_model(model_type)\n",
    "points = [-0.8390980108364587, -0.6963105878638394, -0.8356236712561524, -0.23903240671602388, -0.6054093973324048, -0.13946930067953422, -0.6743069853482686, -0.5732888445600948, -0.9647267833776125]\n",
    "result = predict_arm_position(model, points, model_type)\n",
    "print(f'Prediction: {\"Bent\" if result == 1 else \"Extended\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка точности моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки данных\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[['wrist_x', 'wrist_y', 'wrist_z', 'elbow_x', 'elbow_y', 'elbow_z', 'shoulder_x', 'shoulder_y', 'shoulder_z']]\n",
    "    y = data['label']\n",
    "    return X, y\n",
    "\n",
    "# Функция загрузки модели\n",
    "def load_model(model_type):\n",
    "    if model_type == 'nn':\n",
    "        return tf.keras.models.load_model('../models/model_nn.h5')\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        return joblib.load(f'../models/model_{model_type}.pkl')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting,{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полный процесс обработки данных и обучения моделей\n",
    "\n",
    "В этом ноутбуке мы будем выполнять следующие шаги:\n",
    "1. Генерация датасета.\n",
    "2. Нормализация координат и вычисление углов.\n",
    "3. Обучение моделей (нейросеть, градиентный бустинг, SVM).\n",
    "4. Предсказание с использованием обученных моделей.\n",
    "5. Оценка точности моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Количество образцов для генерации\n",
    "num_samples_per_class = 500\n",
    "\n",
    "# Функция генерации случайных 3D координат\n",
    "def generate_3d_point():\n",
    "    return np.random.uniform(-1, 1, 3)\n",
    "\n",
    "# Функция определения, согнута ли рука\n",
    "def is_bent(shoulder, elbow, wrist):\n",
    "    upper_arm = np.linalg.norm(elbow - shoulder)\n",
    "    forearm = np.linalg.norm(wrist - elbow)\n",
    "    total_length = np.linalg.norm(wrist - shoulder)\n",
    "    return 1 if total_length < (upper_arm + forearm) * 0.95 else 0\n",
    "\n",
    "# Генерация датасета\n",
    "data = []\n",
    "while len(data) < num_samples_per_class * 2:\n",
    "    shoulder = generate_3d_point()\n",
    "    elbow = generate_3d_point()\n",
    "    wrist = generate_3d_point()\n",
    "    label = is_bent(shoulder, elbow, wrist)\n",
    "    if label == 1 and len([d for d in data if d[-1] == 1]) < num_samples_per_class:\n",
    "        data.append(np.concatenate([shoulder, elbow, wrist, [label]]))\n",
    "    elif label == 0 and len([d for d in data if d[-1] == 0]) < num_samples_per_class:\n",
    "        data.append(np.concatenate([shoulder, elbow, wrist, [label]]))\n",
    "\n",
    "# Создание DataFrame\n",
    "columns = ['shoulder_x', 'shoulder_y', 'shoulder_z', \n",
    "           'elbow_x', 'elbow_y', 'elbow_z', \n",
    "           'wrist_x', 'wrist_y', 'wrist_z', \n",
    "           'label']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Сохранение в CSV\n",
    "df.to_csv('../data/raw/dataset.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация координат и вычисление углов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Локальный путь к аннотациям COCO\n",
    "COCO_ANNOTATIONS_PATH = \"../data/person_keypoints_train2017.json\"\n",
    "\n",
    "# Убедитесь, что файл существует\n",
    "if not os.path.exists(COCO_ANNOTATIONS_PATH):\n",
    "    raise FileNotFoundError(f\"File not found: {COCO_ANNOTATIONS_PATH}\")\n",
    "\n",
    "# Загружаем аннотации COCO\n",
    "coco = COCO(COCO_ANNOTATIONS_PATH)\n",
    "\n",
    "# Ключевые точки тела\n",
    "KEYPOINTS = {\"left_shoulder\": 5, \"right_shoulder\": 6,\n",
    "             \"left_elbow\": 7, \"right_elbow\": 8,\n",
    "             \"left_wrist\": 9, \"right_wrist\": 10}\n",
    "\n",
    "# Функция нормализации координат\n",
    "def normalize_coords(coords):\n",
    "    coords = np.array(coords, dtype=np.float32)\n",
    "    min_val, max_val = np.min(coords, axis=0), np.max(coords, axis=0)\n",
    "    return (coords - min_val) / (max_val - min_val)\n",
    "\n",
    "# Функция вычисления угла в локте\n",
    "def elbow_angle(shoulder, elbow, wrist):\n",
    "    vec1 = np.array(elbow) - np.array(shoulder)\n",
    "    vec2 = np.array(wrist) - np.array(elbow)\n",
    "    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0)) * 180 / np.pi\n",
    "    return angle\n",
    "\n",
    "# Создаем DataFrame для хранения данных\n",
    "columns = ['shoulder_x', 'shoulder_y', 'elbow_x', 'elbow_y', 'wrist_x', 'wrist_y', 'angle', 'arm_state']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Выбираем изображения с людьми\n",
    "image_ids = coco.getImgIds(catIds=[1])  # ID людей\n",
    "\n",
    "for image_id in image_ids:\n",
    "    image_data = coco.loadImgs(image_id)[0]\n",
    "    annotation_ids = coco.getAnnIds(imgIds=image_data['id'], catIds=[1])\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "    # Извлекаем координаты ключевых точек\n",
    "    for ann in annotations:\n",
    "        keypoints = ann[\"keypoints\"]\n",
    "        left_shoulder = keypoints[KEYPOINTS[\"left_shoulder\"] * 3:KEYPOINTS[\"left_shoulder\"] * 3 + 2]\n",
    "        left_elbow = keypoints[KEYPOINTS[\"left_elbow\"] * 3:KEYPOINTS[\"left_elbow\"] * 3 + 2]\n",
    "        left_wrist = keypoints[KEYPOINTS[\"left_wrist\"] * 3:KEYPOINTS[\"left_wrist\"] * 3 + 2]\n",
    "\n",
    "        # Нормализуем координаты\n",
    "        norm_coords = normalize_coords([left_shoulder, left_elbow, left_wrist])\n",
    "\n",
    "        # Вычисляем угол\n",
    "        angle = elbow_angle(norm_coords[0], norm_coords[1], norm_coords[2])\n",
    "        arm_state = \"Согнута\" if angle < 150 else \"Разогнута\"\n",
    "\n",
    "        # Добавляем данные в DataFrame\n",
    "        df = df.append({\n",
    "            'shoulder_x': norm_coords[0][0],\n",
    "            'shoulder_y': norm_coords[0][1],\n",
    "            'elbow_x': norm_coords[1][0],\n",
    "            'elbow_y': norm_coords[1][1],\n",
    "            'wrist_x': norm_coords[2][0],\n",
    "            'wrist_y': norm_coords[2][1],\n",
    "            'angle': angle,\n",
    "            'arm_state': arm_state\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Визуализируем\n",
    "        plt.scatter(norm_coords[:, 0], norm_coords[:, 1], color=['r', 'g', 'b'])\n",
    "        plt.plot(norm_coords[:, 0], norm_coords[:, 1], 'k-')\n",
    "        plt.title(f\"Угол: {angle:.2f}° ({arm_state})\")\n",
    "        plt.show()\n",
    "        break  # Только одно изображение\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение данных в CSV файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем DataFrame в CSV файл\n",
    "df.to_csv('../data/normalized_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей (нейросеть, градиентный бустинг, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from models.model import NeuralNetwork\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки данных\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[['wrist_x', 'wrist_y', 'wrist_z', 'elbow_x', 'elbow_y', 'elbow_z', 'shoulder_x', 'shoulder_y', 'shoulder_z']]\n",
    "    y = data['label']\n",
    "    return X, y\n",
    "\n",
    "# Функция обучения нейросети\n",
    "def train_neural_network(X_train, y_train, X_val, y_val):\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    num_classes = 1\n",
    "    model = NeuralNetwork(input_shape, num_classes)\n",
    "    model.build_model()\n",
    "    model.train(X_train, y_train, X_val, y_val)\n",
    "    model.save('../models/model_nn.h5')\n",
    "\n",
    "# Функция обучения градиентного бустинга\n",
    "def train_gradient_boosting(X_train, y_train):\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, '../models/model_gb.pkl')\n",
    "\n",
    "# Функция обучения SVM\n",
    "def train_svm(X_train, y_train):\n",
    "    model = SVC(probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, '../models/model_svm.pkl')\n",
    "\n",
    "# Основная функция\n",
    "def main(model_type):\n",
    "    # Загрузка датасета\n",
    "    X, y = load_data('../data/processed/processed_dataset.csv')\n",
    "    \n",
    "    # Разделение датасета на обучающую и валидационную выборки\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if model_type == 'nn':\n",
    "        train_neural_network(X_train, y_train, X_val, y_val)\n",
    "    elif model_type == 'gb':\n",
    "        train_gradient_boosting(X_train, y_train)\n",
    "    elif model_type == 'svm':\n",
    "        train_svm(X_train, y_train)\n",
    "    else:\n",
    "        print(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting, or 'svm' for support vector machine.\")\n",
    "\n",
    "# Пример вызова функции для обучения нейросети\n",
    "main('nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание с использованием обученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки модели\n",
    "def load_model(model_type):\n",
    "    if model_type == 'nn':\n",
    "        return tf.keras.models.load_model('../models/model_nn.h5')\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        return joblib.load(f'../models/model_{model_type}.pkl')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting, or 'svm' for support vector machine\")\n",
    "\n",
    "# Функция предсказания состояния руки\n",
    "def predict_arm_position(model, points, model_type):\n",
    "    points = np.array(points).reshape(1, -1)\n",
    "    if model_type == 'nn':\n",
    "        prediction = model.predict(points)\n",
    "        return int(np.round(prediction[0][0]))\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        prediction = model.predict(points)\n",
    "        return int(prediction[0])\n",
    "\n",
    "# Пример использования функции предсказания\n",
    "model_type = 'nn'\n",
    "model = load_model(model_type)\n",
    "points = [-0.8390980108364587, -0.6963105878638394, -0.8356236712561524, -0.23903240671602388, -0.6054093973324048, -0.13946930067953422, -0.6743069853482686, -0.5732888445600948, -0.9647267833776125]\n",
    "result = predict_arm_position(model, points, model_type)\n",
    "print(f'Prediction: {\"Bent\" if result == 1 else \"Extended\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка точности моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Функция загрузки данных\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data[['wrist_x', 'wrist_y', 'wrist_z', 'elbow_x', 'elbow_y', 'elbow_z', 'shoulder_x', 'shoulder_y', 'shoulder_z']]\n",
    "    y = data['label']\n",
    "    return X, y\n",
    "\n",
    "# Функция загрузки модели\n",
    "def load_model(model_type):\n",
    "    if model_type == 'nn':\n",
    "        return tf.keras.models.load_model('../models/model_nn.h5')\n",
    "    elif model_type == 'gb' or model_type == 'svm':\n",
    "        return joblib.load(f'../models/model_{model_type}.pkl')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'nn' for neural network, 'gb' for gradient boosting,